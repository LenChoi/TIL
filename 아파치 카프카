1. 카프카 생태계
프로듀셔 / 컨슈머 / 스트림즈 / 커넥트는 아파치 카프카에 포함된 툴이다.

써드파티 라이브러리에서는 카프카의 여러기능을 완벽하게 사용하지 못할 수도 있다.

프로듀서는 데이터를 보내고
컨슈머는 데이터를 처리하고
스트림즈는 프로세싱을 통해 토픽에 있는 데이터를 처리하고 다시 토픽에 보냄
소스 커넥트는 소스애플리케이션으로 부터(Mysql, s3) 토픽에  프로듀셔, 
싱크 커넥터는 타겟 애플리케이션으로 데이터를 보내는 컨슈머 역할

2. 카프카 브로커와 클러스터
카프카 클러스터 하나에는 여러개의 브로커가 존재한다.
상용에서는 3개정도 사용

클러스터를 2,3개 사용하는 경우도 있음
브로커 한대로도 사용이 가능하지만 데이터를 안전하게 처리하려면 
3개의 브로커를 하나의 클러스터로 묶어서 사용한다.

클러스터를 실행하기 위해서는 주키퍼가 필요
각각 다른팀이 클러스터를 하나씩 운영하면서 주키퍼 앙상블로 여러개의 클러스터를 운영 할 수 있다.

3.0부터는 주키퍼 없어도 클러스터 동작이 가능

3. 브로커의 역할 - 컨트롤러, 데이터 삭제
브로커에 장애 발생시 다른 브로커로 리더 파티션을 재분배 하는 역할을 컨트롤러가 한다
비정상일떄는 빠르게 클러스터에서 뺴내는 것이 중요.

컨슈터가 데이터를 가져가더라도 토픽의 데이터는 삭제되지 않는다.
오직 브로커만 데이터를 삭제할 수 있고 데이터 삭제는 파일 단위로 이루어지는데 이 단위를
'로그 세그먼트'라고 부른다.

컨슈머 오프셋을 저장한다.
컨슈머가 몇번 오프셋까지 처리했는지 확인해기위해 오프셋을 커밋한다.
__consumer_offsets 토픽에 저장
여기에 저장된 오프셋을 토대로 컨슈머 그룹은 다음 레코드를 가져가서 처리한다.

그룹 코디네이터
컨슈머 그룹의 상태를 체크하고 파티션을 컨슈머와 매칭되도록 분배하는 역할.
컨슈머가 컨슈머 그룹에서 빠지면 매칭되지 않는 파티션을 정상 동작하는 컨슈머로 할당하여 끊임없이 데이터가 처리되도록 도와준다.
이 과정을 '리밸런스'라고 함.

4. 브로커의 역할 - 데이터의 저장
카프카를 실행할 때 config/server.prperties의 log.dir에 정의한 디렉토리에 데이터를 저장.
토픽 이름과 파티션 번호의 조합으로 하위 디렉토리를 생성하여 데이터를 저장
log에는 메시지와 메타데이터를 저장
index는 메시지의 오프셋을 인덱싱한 정보를 담은 파일
timeindex 파일에는 메시지에 포함된 timestamp값을 기준으로 인덱싱한 정보가 담겨 있음.

log.segment.bytes: 바이트 단위의 최대 세그먼트 크기 지정. 기본값은 1GB
log.roll.ms(hours): 세그먼트가 신규 생성된 이후 다음 파일로 넘어가는 시간 주기. 기본 값은 7일

00000010.log는 오프셋 10부터의 레코드가 저장되어 있다.

쓰기가 일어나고 있는 세그먼트를 액티브 세그먼트라고 부른다.
엑티브 세그먼트는 삭제 대상에 포함되지 않는다.
리텐션 옵션에 따라 액티브를 제외한 세그먼트는 삭제 대상으로 지정된다.

5. 세그먼트와 삭제 주기
retention.ms: 세그먼트를 보유할 최대 기간(기본 7일) - 보통 3일로 잡는다
retention.bytes: 파이션당 로그 잭재 바이트 값, 기본 값은 -1(지정하지 않음)
log.retention.check.interval.ms: 세그먼트가 삭제 영역에 들어왔는지 확인하는 간격. (기본 5분)

레코드(오프셋)단위로 삭제가 불가능하고 수정도 불가능하다. 세그먼트 단위로 삭제만 가능하다.

6. cleanup.policy=compact
레코드에는 메시지 키, 벨류가 있음
컴팩트일 경우는 메시지 키를 단위로 가장 최근 메시지만 남긴다.
이때도 액티브는 제외
만약 통계처럼 가장 최신의 데이터를 이용하는 경우 과거꺼는 필요 없기 때문에 컴팩트로 활용하면 좋다.

테일 영역: 압축 정책에 의해 압축이 완료된 레코드. 클린로그 라고 부른다.
헤드 영역: 압축 정책이 되기 전 레코드. 더티로그 라고도 부른다. 중복된 메시지 키가 있다.

min.cleanable.dirty.ratio
헤드 영역: 압축 정책이 되기 전 레코드. 더티로그 라고도 부른다. 중복된 메시지 키가 있다

테일과 헤드의 레코드 개수 비율로 압축을 실행한다.
0.5로 설정하면 테일과 헤드 레코드 개수가 동일 한 경우 압축이 실행된다.
비율이 0.9이면 한번에 많은 데이터가 줄어들어 효과는 좋지만 용량을 많이 차지한다.

7. 브로커의 역할 - 복제(Replication)
카프카 장애 허용 시스템으로 동작하도록 하는 원동력이다.
클로스터로 묶인 브로커 중 일부에 장애가 발생하더라도 데이터를 유실하지 않고 안전하게 사용할 수 있다.
카프카의 데이터 복제는 파티션 단위로 이루어진다.
복제 개수의 최소값은 1(복제 없음) 최대값은 브로커 개수만큼 설정하여 사용할 수 있다.

보통 상용에서는 2,3정도로 사용

파티션(리더)에 저장이 되고 다른 브로커의 파티션(팔로워)에 복제된다.
리더의 오프셋에 팔로워가 비교하여 지속적으로 가져간다.(복제)

프로듀셔가 데이터를 가져갈 때는 팔로워에 가져가는게 아니고 리더만 통신하여 가져간다.
따라서 리더 브로커가 다운되면 팔로워 파티션이 승급하여 리더가 되어 통신한다.

네비게이션의 gps를 받는다고 하면 1분에 60개 받는 것중 2,3개 유실되어도 괜찮기 때문에
이럴때는 레플리케이션을 1로 설정한다.
금융정보 같은 것은 3으로도 설정한다.

8. ISR(In-Sync-Replicas)
리더와 팔로워가 모두 싱크된 상태

ISR이 안되었는데 장애가 나면 리더의 데이터가 유실 될 수 있다.
이럴때 팔로워 파티션을 리더로 선출 할 것인지 정하는 것이
unclean.leader.election.enable이다
true이면 ISR 안 된 것도 리더로 선출(유실을 감수함)
false인 경우 해당 브로커가 복구될 때까지 중단

9. 토픽과 파티션
토픽은 카프카에서 데이터를 구분하기 위해 사용되는 단위.
토픽은 1개의 이상의 파티션을 소유하고 있다. 파티션에는 프로듀서가 보낸 데이터들이 들어가 저장되는데
이 데이터를 ‘레코드’라고 부른다. 파티션은 자료구조에서 접하는 큐와 비슷한 구조.
먼저들어간 레코드는 컨슈머가 먼저 가져가게 된다. 다만 큐와 다르게 삭제하지 않는다

토픽 생성시 파티션이 브로커들에 라운드로빈 방식으로 순차적으로 균등하게 리더 파티션들이 생성된다.
균등하게 통신하여 네트워크를 골고루 사용하게 된다.

특정 브로커에 만약 몰르게되면 kafka-reassign-partitions.sh 명령으로 파티션을 재분배할 수 있다.

컨슈며와 파티션은 1대1 관계이다. 파티션은 하나의 컨슈머만 가질 수 있다.
컨슈머의 데이터 처리량을 늘리기 위해서는 파티션을 늘리고 컨슈머를 늘려야한다.

만약 장애 발생 시 하나의 컨슈머가 여러개의 파티션을 처리 할 수도 있다. 

프로듀서는 초당 10개를 보내는데 컨슈머는 초당 1개만 처리할때는 렉이 발생된다
이때는 컨슈머를 10개 늘리고 파티션을 10개 늘려야 한다. 보통 여유롭게 운용해야 함.

파티션 개수를 줄이는 것은 불가능. 

오프셋은 프로듀서가 생성한 레코드에는 존재하지 않고 프로듀서가 전송한 레코드가 브로커에 적재될 떄 오프셋이 지정. 0부터 시작되고 1씩 증가한다.

메시지 키는 처리하고자 하는 메시지 값을 분류하기 위한 용도로 사용되며, 이를 파티셔닝이라고 부름
메시지 키는 파티셔너에 따라 토픽의 파티션 번호가 정해진다.
메시지 키는 필수 값이 아니며 지정하지 않으면 null이다.
메시지 키가 null인 경우는 라운드 로빈으로 파트션에 전달된다.
Null이 아닌 경우 해쉬값에 의해 특정 파티션에 들어간다. 사과 라는 단어는 항상 동일한 파티션에 들어간다.
이럴경우는 같은 파티션에 저장되어 순서보장이 된다.

10. 클라이언트 메타데이터
카프카 클라이언트는 통신하고자하는 리더 파티션의 위치를 알기 위해 데이터를 주고 받기 전에 메타데이터를 브로커로부터 전달 받는다.

메타데이터를 지속적으로 응답받지 못하면 리더 파티션과 통신 할 수 없다.

metadata.max.age.ms: 메타데이터를 강제로 리프래시 하는 간격(기본 5분)
metadata.max.idle.ms: 프로듀서가 유휴 상태일 경우 메타데이터를 캐시에 유지하는 기간

leader_not_available 에러가 발생하면 메타데이터 문제라 자주 리프래시 할 수 있게 한다.




토픽을 생성 할 수 있다.
Bin/kafka-topics.sh —create —bootstrap-server my-kafka:9092 —topic hollo.kafka

토픽 정보 확인 가능
Bin/kafka-topics.sh —bootstrap-server my-kafka:9092 —topic hello.kafka —describe


파티션 개수 늘리기
Bin/kafka-topics.sh —bootstrap-server my-kafkaL9092 —topic test —alter —partitions 4

파티션 줄이는 것은 엄청 복잡해 아직은 지원하지 않는다.

카프카 토픽에 데이터를 넣기
bin/kafka-console-producer.sh --bootstrap-server my-kafka:9092 --topic hello.kafka

Parse key 옵션을 주지 않으면 메시지 키는 null로 설정되고 파티션에 라운드 로빈으로 들어가게 된다.

bin/kafka-console-producer.sh --bootstrap-server my-kafka:9092 --topic hello.kafka —property “parse.key=true” —property “key.separator=:”




Kafka-console-consumer.sh
특정 토픽에 있는 데이터를 컨슘해서 임시적으로 조회 하기 위한 용도

—from-beginning 옵션을 주면 토픽에 저장된 가장 가장 오래된 데이터부터 출력

키 출력
—property print.key=true 

키와 벨류 사이에 구분자
—property key.separator=“-“

—max-messages 옵션을 사용하면 최대 컨슘 메시지 개수를 설정
 
—partition 옵션을 사용하면 특정 파티션만 컴슘할 수 있다.


특정 파티션만 컨슘 가능
—partition

bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092 --topic hello.kafka --property print.key=true --property key.separtator="-" --from-beginning --max-messages 3 --partition 0



Kafka-consumer-groups.sh

오프셋 리셋 종류
—to-earliest: 가장 처음 오프셋으로 리셋
—to-latest: 가장 마지막 오프셋으로 리셋
—to-current: 현 시점 기준 오프셋으로 리셋
—to-datetime: 특정 일시로 오프셋 리셋
—to-offset: 특정 오프셋으로 리셋
—shift-by: 현재 컨슈머 오프셋에서 앞으로 옮겨서 리셋

bin/kafka-consumer-groups.sh --bootstrap-server my-kafka:9092 --group hello-group --describe

가장 처음의 오프셋부터 읽게 초기화
bin/kafka-consumer-groups.sh --bootstrap-server my-kafka:9092 --group hello-group --topic hello.kafka --reset-offsets --to-earliest --execute



Kafka-producer-perf-test.sh
카프카 프로듀서로 퍼포먼스를 측정할 떄 사용. 카프카 브로커와 컨슈머 간의 네트워크를 체크할 때 사용 할 수 있다.

Kafka-reassign-partitions.sh
리더 파티션이 한 곳으로 몰릴 경우 재할당


Kafka-delete-record.sh
특정 파티션의 오프셋 번호 이하만큼을 다 지운다.

Kafka-dump-log.sh
인덱스, 로그, 타임인덱스 등 세그먼트 단위로 들어 있다.

카프카 브로커와 로컬 커맨드 라인 툴 버전이 맞아야 한다.





프로듀서
카프카에서 데이터의 시작점은 프로듀서이다.
자바만 공식 라이브러리로 사용된다. 다른언어는 성능이나 기능이 다를 수 있음.

프로듀서 내부 구조
- 프로듀서레코드: 프로드서에서 생성하는 레코드. 오프셋은 미포함
- send(): 레코드를 전송 요청 메서드
- Petitioner: 어느 파티션으로 전송할지 지정하는 파티셔너
- Accumulator: 배치로 묶어 전송할 데이터를 모으는 버퍼
- 

프로듀서의 기본 파티셔너
1. RoundRobinPartitioner
2. UniformStickyPartitioner: 어큐뮤레이터에서 레코드들이 배치로 묶을 떄까지 기다렸다가 전송, 배치로 묶일 뿐 결국 파티션 순회
3. 커스텀 파티셔너

카프카 클라이언트 라이브러리에 서는 사용자 지정 파티셔너를 생성하기 위한 Partitioner를 제공한다.
인터페이스를 상속 후 파티션 지정 로직을 적용 할 수 있다.

프로듀서 주요 옵션(필수 옵션)
Bootstrap.server: 프로듀서가 데이터를 전송할 대상 카프카 클러스터에 속한 브로커의 호스트 이름: 포트를 1개 이상 작성한다. 2개 이상 입력해 일부 브로커에 이슈가 발생하더라도 접속하는데 이슈가 없도록 설정

- Key.serializer: 레코드의 메시지 키를 직렬화 하는 클래스를 지정
- Value.serializer: 레코드의 메시지 값을 직렬화하는 클래스를 지정



acks옵션은 0, 1, all(-1) 값을 가질 수 있다.
복제 개수가 1인 경우 ACKS옵션에 따른 성능 변화는 크지 않다. 복제 개수가 2 이상인 경우 ACKS별 동작 방식에 대해 알아보자

acks=0
프로듀서가 리더 파티션으로 데이터를 전송했을 때 리더파이션으로 데이터가 저장되었는지 확인하지 않는다.
SEND()메서드만 실행, 가장 속도가 빠르다. 신뢰도가 낮음

acks=1
프로듀서가 보낸 데이터가 리더 파티션에만 정상적으로 적재되었는지 확인
만약 적재되지 않았다면 리더 파티션에 적재될 때까지 재시도할 수 있다.
정말 큰 이슈가 아닌 이상 렉이 딱히 발생하지 않았다. 이걸로도 충분함


acks=-1
프로듀서가 리더와 팔로워 둘다 정상적으로 적재되었는지 확인. 속도가 느리다(신뢰도가 높다)



컨슈머 내부 구조

카프카 클러스터에서 리더 파티션에 있는 브로커가 데이터를 보내면 패처가 데이터를 받게 된다.
데이터를 충분히 받겓괴면  poll()을 통해 ConsumerRecords로 받게 된다(리스트로 받음)

ConsumerRecords에는 오프셋이 포함되어 있음

처리가 완료되면 commit을 통해 컨슈머가 완료되었는지 알수 있다.


컨슈머 그룹
특정 토픽에 대해 어떤 목적에 따라 컨슈머를 묶은 그룹이다.
동일한 컨슈머 그룹을 가진 컨슈머들은 동일한 로직을 가진 컨슈머들이다.

어떤 컨슈머 그룹이 가져 가도 컨슈머 그룹이 새로 만들어 지면 모든 데이터를 가져 갈 수 있다.

만약 4개의 컨슈머로 이루어진 컨슈머 그룹이 3개의 파티션을 가진 토픽에서 데이터를 가기위해 할당하면
1개의 컨슈머는 파티션을 할당받지 못하고 유휴 상태로 남게 된다.



리밸런싱
토픽과 컨슈머의 할당 과정이 변경되는 과정

파티션과 컨슈머가 1대1로 대응되고 있는데 컨슈머에 장애가 발생하면 데이터 처리에 지연이 생길 수 있다.
리텐션 지나면 유실도 가능.
따라서 장애가 발생하면 파티션에 컨슈머 재 할당이 필요하다.


커밋
컨슈머는 카프카 브로커로부터 데이터를 어디까지 가져갔는지 커밋을 통해 기록한다.
특정 토픽의 파티션을 어떤 컨슈머 그룹이 몇 번쨰 가져갔는지 카프카 브로커 내부에서 사용되는 내부 토픽에 기록
커밋에 정상적으로 처리되지 않으면 데이터 처리에 중복이 생길 수 있다. 

어싸이너(Assignor)
컨슈머와 파티션 할당 정책은 컨슈머의 어싸이너에 의해 결정

RangeAssignor: 각 토픽에서 파티션을 숫자로 정렬, 컨슈머를 사전 순서로 정렬하여 할당.(기본 값)
RoundRobinAssignor: 모든 파티션을 컨슈머에서 번갈아가면서 할당
StrickyAssignor: 최대한 파티션을 균등하게 배분하면서 할당


컨슈머 주요 옵션(필수 옵션)
bootstrap.servers: 프로듀서가 데이터를 전송할 대상 카프카 클러스터에 속한 브로커의 소프트
key.deserializer: 레코드의 메시지 키를 역직렬화하는 클래스 지정
value.deserializer: 레코드의 메시지 값을 역직렬화 하는 클래스를 지정

직렬화 해서 토픽에 저장하는데 컨슈머가 처리할 때는 역직렬화 해야 한다.

만약 스트링으로 직렬화 했는다 다른 포멧으로 역직렬화 하면 안된다.


컨슈머 주요 옵션(선택 옵션)
group.id: 컨슈머 그룹 아이디를 지정. subscribe() 메서드로 토픽을 구독하는 경우 이것은 필수, 기본값은 null
auto.offset.reset: 컨슈머 그룹이 특정 파티션을 읽을 때 컨슈머 오프셋이 없는 경우(한번도 커밋이 없는경우) 어떤 오프셋부터 읽을지 선택
enable.auto.commit: 자동/수동 커밋 선택(기본값 true)
auto.commit.interval.ms: 자동 커밋일 경우 오프셋 커밋 간격을 지정(기본 5초 5000)
max.poll.records: poll() 메서드를 통해 반환되는 레코드 개수를 지정 (기본값은 500)
session.timeout.ms: 컨슈머가 브로커와 연결이 끊기는 최대 시간(기본10초10000)
Heartbeat.interval.ms: 하트비트를 전송하는 시간 간격이다.(기본값은 3초 3000)

하트비트를 보낸 후 만약 10초간 반응이 없으면 연결이 끊킨다.

max.poll.interval.ms: poll() 메서드를 호출하는 간격의 최대 시간. (기본값은 5분 300000)
isolation.level: 트랜잭션 프로듀서가 레코드를 트랜잭션 단위로 보낼 경우 사용.


auto.offset.reset 좀더 알아보기
특정 컨슈머 애플리케이션이 실행되었을때 가장 오래된 오프셋 부터 읽을지 가장 최근의 오프셋 부터 읽을지 지정할 수 있다.
만약 커밋을 한 기록이 있으면 이것은 무시된다.

latest로 설정하면 가장 최근에 넣은 오프셋부터 읽음(기본값)
earliest는 가장 오래된 오프셋부터 0번부터 ~~~
none은 컨슈머 그룹이 커밋한 기록이 있는지 찾아보고 커밋이 없으면 오류를 반환

처음 새로운 컨슈머를 운영할때만 필요하지 그 이후로는 필요하지 않은 옵션이다.


동기 오프셋 커밋을 사용할 경우 커밋 응답을 기다리는 동안 데이터 처리가 일시적으로 중단 되기 때문에 더 많은 데이터를 처리하기 위해 비동기 오프셋 커밋을 사용할 수 있다.
consumer.commitAsync() - 비동기
consumer.commitSync() - 동기



컨슈머의 안전한 종료
정상적으로 종료되지 않은 컨슈머는 세션 타임아웃이 발생할떄까지 컨슈머 그룹에 남게 된다.
컨슈머를 안전하게 종료하기 위해 wakeup() 메서드를 제공
카프카 컨슈머 인스턴스를 wakeup()으로 안전하게 종료 할 수 있다.
wakeup() 메서드가 실행된 이후에 poll() 메서드를 호출하면 WakeupException 예외가 발생한다.



프로듀서가 데이터를 많이 보애는데 컨슈머가 처리하는 속도가 늦으면 컨슈머 랙이 발생 할 수 있다.

컨슘머 애플리케이션을 운영하면 컨슈머 랙을 필수로 모니터링 해야 한다. 컨슈머 랙은 컨슈머 그룹과 토픽, 파티션별로 생성된다.
컨슈머 그룹의 개수가 늘어나면 모니터링 해야 하는 컨슈머 랙이 늘어난다.


Kafka-consumer-group.sh 명령어를 사용하면 컨슈머 랙을 토함한 특정 그룹의 상태를 확인 할 수 있다.
Bin/kafka-consumer-groups.sh —bootstrap-server my-kafka:9092 —group my-group —describe

KafkaConsumer 인스턴스의 metrics() 메서드를 활용하면 컨슈머 랙 지표를 확인 할 수 있다.
컨슈머가 정상 동작할 경우만 확인 할 수 있는 단점이 있다. 만약 컨슈머 애플리케이션이 비정상적으로 종료되면 더는 컨슈머 랙을 모니터링 할 수 없다.


외부 모니터링 툴 사용 하는게 제일 좋다
데이터독, 컨플루언트 컨트롤 센터

컨슈머 랙 모니터링만을 위한 오픈소스로 버로우(burrow)가 있음




멱등성 프로듀서
멱등성이란 여러 번 연산을 수행하더라도 동일한 결과를 나타낸다는 것을 뜻한다.
멱등성 프로듀서는 동일한 데이터를 여러번 전송하더라도 카프카 클러스터에 단 한번만 저장됨을 의미

기본 프로듀서의 동작 방식은 적어도 한번 전달을 지원한다.

Enable.idemptoence 옵션을 사용하여 정확히 한번 전달을 지원.
옵션의 기본값은 false()이다. 정확히 한번 전달을 위해서는 true로 옵션값을 설정해서 멱등성 프로듀서로 동작하도록 만들자


카프카 3.0.0부터는 true로 기본 설정되고 acks=all로 변경된다.

멱등성 프로듀서는 기본 프로듀서와 달리 데이터를 브로커로 전달할 때 프로듀서 pid(유니크 아이디)와 시퀀스 넘버를 함께 전달한다.
이것을 통해 동일한 메시지의 적재 요청이 오더라도 한번만 데이터를 저장

멱등성 프로듀서는 동일한 세션에서만 정확히 한번 전달을 보장.
비정상 종료일 경우 보장하지 못한다. 동일한 레코드 더라도 비정상 종료되어 Pid가 변경되면 인지하지 못한다.

enable.idempotence를 true로 설정하면 데이터 재전송 횟수를 정하는 retries는 기본값으로 inter.MAX_VALUE로 설정되로 acks옵션은 all이 된다. 




트랜잭션 컨슈머는 커밋이 완료된 레코드들만 읽기 위해 isolation.level 옵션을 read_committed로 설정해야 한다. 기본 값은  read_uncommitted로서 커밋 여부와 상관 없이 모두 읽는다.



카프카 스트림즈

스트림즈 애플리케이션 또는 카프카 브로커의 장애가 발생하더라도 정확히 한번 할 수 있도록 장애 허용 시스템을 가지고 있어서 데이터 처리 안정성이 매우 뛰어나다.
카프카 클러스터를 운영하면서 실시간 스트림 처리를 해야하는 필요성이 있다면 카프카 스트림즈 애플리케이션으로 개발하는 것을 1순위로 고려하는 것이 좋다.

스티름 데이터 처리에 있어 필요한 다양한 기능을 스트림즈 DSL로 제공하며 필요하다면 프로세서 API 를 사용하여 기능을 확장할 수 있다.
스트림즈 라이브러리를 통해 제공하는 단 한번의 데이터 처리, 장애 허용 시스템 등의 특징들은 컨슈머와 프로듀서의 조합만으로는 완벽하게 구현하기 어렵다.

소스 토픽과 싱크 토픽의 카프카 클러스터가 서로 다른 경우는 스트림즈가 지원하지 않으므로 이떄는 프로듀서 조합으로 직접 클러스터를 지정하는 방식으로 개발 할 수 있음


스트림즈 내부 구조

파티션에 1대1 대응하여 태스크가 매칭되어 있다. 스트림즈의 태스크는 스트림즈 애플리케이션을 싱행하면 생기는 데이터 처리 최소 단위.
컨슈머의 병렬처리를 위해 컨슈머 그룹으로 이루어진 컨슈머 스레드를 여러개 실행하는 것과 비슷함.
카프카 스트림즈는 컨슈머 스레드를 늘리는 방법과 동일하게 병렬처리를 위해 파티션과 스트림즈 스테드 개수를 늘림으로써 처리량을 늘릴 수 있다.


토폴로지

2개 이상의 노드들과 선으로 이루어진 집합.

링형 토폴로지
트리형 토폴로지
성형 토폴로지

카프카 스트림즈에서는 토폴로지를 이루는 노드 하나를 프로세서 라고 부르고 노드와 노드를 이은 선을 스트림 이라고 부른다.

프로세서는
소스 프로세서: 데이터를 처리하기 위해 최초로 선언해야 하는 노드, 하나 이상의 토픽에서 데이터를 가져오는 역할
스트림 프로세서: 데이터를 처리하는 역할. 변환/분기처리와 같은 로직이 데이터 처리의 일종
싱크 프로세서: 특정 카프카 토픽으로 저장하는 역할. 스트림즈로 처리된 데이터의 최종 종착지이다.


스트림즈DSL과 프로세서 API

스트림즈DSL: 스트림 프로세싱에 쓰일 만한 다양한 기능들을 자체 API 로 만들어 놓아 대부분의 변환 로직을 어렵지 않게 개발 가능
만약 스트림즈DSL에서 제공하지 않는 일부 기능들의 경우 프로세서 API를 사용하여 구현 가능


스트림즈DSL로 구현하는 데이터 처리 예시
- 메시지 값을 기반으로 토픽 분기 처리
- 지난 10분간 들어온 데이터의 개수 집계

프로세서API로 구현하는 데이터 처리 예시
- 메시지 값의 종류에 따라 토픽을 가변적으로 전송
- 일정한 시간 간격으로 데이터 처리

스트림즈 DSL에는 레코드의 흐름을 추상화한 3가지 개념인 Stream, KTable, GlobalKTable이 있다.
카프카 토픽에 있는 데이터를 어떤 형태로 선언할 것인지에 따라 추상화한 개념이다.


KStream: 레코드의 흐름을 표현한 것 메시지키와 메시지 값으로 구성, 이것으로 데이터를 조회하면 토픽에 존재하는 모든 레코드가 출력된다.
컨슈머로 토픽을 구독하는 것과 동일 선상에서 사용하는 것. 데이터를 하나씩 처리

KTable: 유니크한 메시지 키를 기준으로 가장 최신 레코드를 사용한다. 새로 데이터를 적재할 때 동일한 메시지 키가 있는 겨우 데이터가 업데이트 되었다고 볼 수 있음.
가장 최신의 데이터만 유지하고 있을때 이것을 사용. Ex) 사용자의 주소 - 이전의 주소는 필요 없기 때문에

코파티셔닝
KStream과 KTable을 조인하려면 반드시 코파티셔닝되어 있어야 한다. 조인하는 2개의 데이터의 파티션 개수가 동일하고 파티셔닝 전략을 동일하게 맞추는 작업이다.

토픽A(KStream) 파티션 2개 , 토픽B(KTable) 파티션 3개 인 경우 1. 파티션 개수동일 2. 파티셔닝 전략 같이야 하는데
파티션 개수가 다르기 때문에 조인이 불가능하다. 코파티션이 되지 않는다.

GlobalKTable
코파티셔닝 되지 않은 KStream과 데이터 조인을 할 수 있다. 왜냐하면 KTable과 다르게 데이터 스트림즈 애플리케이션의 모든 태스크에 동일하게 공유되어 사용된다.

만약 글로벌 테이블이 비대하면 각각의 태스크가 모든 데이터를 가져 있기 때문에 굉장히 큰 용량이 필요하다 따라서 글로벌 케이 테이블은 데이터 량이 충분히 작거나 리텐션 기간을 잘 조절해서 사용해야 한다.

글로벌 K 테이블은 모든 데이터가 각각의 태스크에 들어간다는 것이 다르다.



스트림즈 DSL 중요 옵션(필수 옵션)

- bootstrap.servers: 프로듀서가 데이터를 전송할 대상 카프카 클러스터 브로커의 호스트 이름
- application.id: 스트림즈 애플리케이션을 구분하기 위한 고유 아이디. 다른 로직을 가진 스트림즈 애플리케이션들은 서로 다른 application.id를 가진다

선택 옵션
- default.key.serde: 레코드의 메시지 키를 직렬화, 역직렬화 하는 클래스를 지정, 기본값은 바이트 직렬화 , 역직렬화 클래스dls Serdes.ByteArray().getClass().getName()
- default.value.serde: 레코드의 메시지 값을 직렬화, 역직렬화
- num.stream.threads: 스트림 프로세싱 실행 시 실행될 스레드 개수 지정
- state.dir: 상태 기반 데이터 처리를 할 때 데이터를 저장할 디렉토리를 지정한다. 기본값은 /tmp/kafka-streams

KTable과 KStream은 메시지 키를 기준으로 조인할 수 있다.  대부분의 데이터베이스는 정적으로 저장된 데이터를 조인하여 사용했지만 카프카에서는 실시간으로 들어오는 데이터들을 조인 할 수 있다. 사용자의 이벤트 데이터를 데이터베이스에 저장하지 않고도 조인하여 스트리밍 처리할 수 있다는 장점이 있다.
만약 stream()에 주문데이터가 계속 들어오고 table()에 주소 가 있다면 주문데이터와 주소를 조인해 사용 가능


카프카 토픽을 만들 떄 부터 kTABLE, KStream을 만들 필요는 없다.

KTable과 KStream의 메시지 키가 같으면 조인을 실행한다. 우리가 따로 설정하는 것이 아님

코파티션: 파티션 개수 동일/ 파티셔닝 전략 동일

코파티션이 되지 않으면 글로벌 케이테이블 활용

코파티셔닝 되어 있지 않은 데이터를 조인 하는 방버은
1. 리파티셔닝을 수행한 후에 코파티셔닝이 된 상태로 조인 처리
2. KTable로 사용하는 토픽을 GlobalKTable로 선언하여 사용


스트림즈 DSL - window processing

스트림 데이터를 분석할 때 가장 많이 활용하는 프로세싱 중 하나는 윈도우 연산이다.윈도우 연산은 특정 시간에 대응하여 취합 연산을 처리할 떄 활용한다.
그러므로 해당 토픽에 동일한 파티션에는 동일한 메시지 키가 있는 레코드가 존재해야지만 정확한 취합이 기능하다.
만약 커스텀 파티셔너를 사용하여 동일한 메시지 키가 동일한 파티션에 저장되는 것을 보장하지 못하거나 메시지 키를 넣지 않으면 관련 연산이 불가능

- 텀블링 윈도우: 서로 겹치지 않은 윈도우를 특정 간격으로 지속적으로 처리할 때 사용, 윈도우 최대 사이즈에 도달하면 해당 시점에 데이터를 취합하여 결과를 도출, 예를들어 5분간 접속한 고객의 수를 측정하여 방문자 추이를 실시간 취합하는 경우 텀블링 윈도우 사용 가능

- 호핑 윈도우: 윈도우가 일정 시간 간격으로 겹치는 경우 사용, 텀블링 윈도우와 다르게 동일한 키의 데이터는 서로 다른 윈도우에서 여러번 연산 가능

- 슬라이딩 윈도우: 호핑과 유사하지만 데이터의 정확한 시간을 바탕으로 윈도우 사이즈에 포함되는 데이터를 모두 연산에 포함
- 세션 윈도우: 동일한 메시지 키의 데이터를 한 세션에 묶어 연산할 떄 사용. 세선의 최대 만료시간에 따라 윈도우 사이즈가 달라진다. 그렇기 때문에 세션 윈도우의 윈도우 사이즈는 가변적이다.

프로세서 API
스트림즈 DSL보다 투박한 코드를 가지지만 토폴로지를 기준으로 데이터를 처리한다는 관점에서는 동일하다.
프레서서 API 에서는 KStream 등의 개념이 없다. 다만 스트림드DSL 과 함께 사용 가능하다.

프로서세API 를 구현하기 위해서는 Processor 또는 Transformer 인터페이스로 구현한 클래스가 필요하다.
Processor 인터페이스는 일정 로직이 이루어진 뒤 다음 프로세서로 데이터가 넘어가지 않을 때 사용한다.
Transformer 인터페이스는 일정 로직이 이루어진 뒤 다음 프로세서로 데이터를 넘길 떄 사용한다.
