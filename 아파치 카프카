1. 카프카 생태계
프로듀셔 / 컨슈머 / 스트림즈 / 커넥트는 아파치 카프카에 포함된 툴이다.

써드파티 라이브러리에서는 카프카의 여러기능을 완벽하게 사용하지 못할 수도 있다.

프로듀서는 데이터를 보내고
컨슈머는 데이터를 처리하고
스트림즈는 프로세싱을 통해 토픽에 있는 데이터를 처리하고 다시 토픽에 보냄
소스 커넥트는 소스애플리케이션으로 부터(Mysql, s3) 토픽에  프로듀셔, 
싱크 커넥터는 타겟 애플리케이션으로 데이터를 보내는 컨슈머 역할

2. 카프카 브로커와 클러스터
카프카 클러스터 하나에는 여러개의 브로커가 존재한다.
상용에서는 3개정도 사용

클러스터를 2,3개 사용하는 경우도 있음
브로커 한대로도 사용이 가능하지만 데이터를 안전하게 처리하려면 
3개의 브로커를 하나의 클러스터로 묶어서 사용한다.

클러스터를 실행하기 위해서는 주키퍼가 필요
각각 다른팀이 클러스터를 하나씩 운영하면서 주키퍼 앙상블로 여러개의 클러스터를 운영 할 수 있다.

3.0부터는 주키퍼 없어도 클러스터 동작이 가능

3. 브로커의 역할 - 컨트롤러, 데이터 삭제
브로커에 장애 발생시 다른 브로커로 리더 파티션을 재분배 하는 역할을 컨트롤러가 한다
비정상일떄는 빠르게 클러스터에서 뺴내는 것이 중요.

컨슈터가 데이터를 가져가더라도 토픽의 데이터는 삭제되지 않는다.
오직 브로커만 데이터를 삭제할 수 있고 데이터 삭제는 파일 단위로 이루어지는데 이 단위를
'로그 세그먼트'라고 부른다.

컨슈머 오프셋을 저장한다.
컨슈머가 몇번 오프셋까지 처리했는지 확인해기위해 오프셋을 커밋한다.
__consumer_offsets 토픽에 저장
여기에 저장된 오프셋을 토대로 컨슈머 그룹은 다음 레코드를 가져가서 처리한다.

그룹 코디네이터
컨슈머 그룹의 상태를 체크하고 파티션을 컨슈머와 매칭되도록 분배하는 역할.
컨슈머가 컨슈머 그룹에서 빠지면 매칭되지 않는 파티션을 정상 동작하는 컨슈머로 할당하여 끊임없이 데이터가 처리되도록 도와준다.
이 과정을 '리밸런스'라고 함.

4. 브로커의 역할 - 데이터의 저장
카프카를 실행할 때 config/server.prperties의 log.dir에 정의한 디렉토리에 데이터를 저장.
토픽 이름과 파티션 번호의 조합으로 하위 디렉토리를 생성하여 데이터를 저장
log에는 메시지와 메타데이터를 저장
index는 메시지의 오프셋을 인덱싱한 정보를 담은 파일
timeindex 파일에는 메시지에 포함된 timestamp값을 기준으로 인덱싱한 정보가 담겨 있음.

log.segment.bytes: 바이트 단위의 최대 세그먼트 크기 지정. 기본값은 1GB
log.roll.ms(hours): 세그먼트가 신규 생성된 이후 다음 파일로 넘어가는 시간 주기. 기본 값은 7일

00000010.log는 오프셋 10부터의 레코드가 저장되어 있다.

쓰기가 일어나고 있는 세그먼트를 액티브 세그먼트라고 부른다.
엑티브 세그먼트는 삭제 대상에 포함되지 않는다.
리텐션 옵션에 따라 액티브를 제외한 세그먼트는 삭제 대상으로 지정된다.

5. 세그먼트와 삭제 주기
retention.ms: 세그먼트를 보유할 최대 기간(기본 7일) - 보통 3일로 잡는다
retention.bytes: 파이션당 로그 잭재 바이트 값, 기본 값은 -1(지정하지 않음)
log.retention.check.interval.ms: 세그먼트가 삭제 영역에 들어왔는지 확인하는 간격. (기본 5분)

레코드(오프셋)단위로 삭제가 불가능하고 수정도 불가능하다. 세그먼트 단위로 삭제만 가능하다.

6. cleanup.policy=compact
레코드에는 메시지 키, 벨류가 있음
컴팩트일 경우는 메시지 키를 단위로 가장 최근 메시지만 남긴다.
이때도 액티브는 제외
만약 통계처럼 가장 최신의 데이터를 이용하는 경우 과거꺼는 필요 없기 때문에 컴팩트로 활용하면 좋다.

테일 영역: 압축 정책에 의해 압축이 완료된 레코드. 클린로그 라고 부른다.
헤드 영역: 압축 정책이 되기 전 레코드. 더티로그 라고도 부른다. 중복된 메시지 키가 있다.

min.cleanable.dirty.ratio
헤드 영역: 압축 정책이 되기 전 레코드. 더티로그 라고도 부른다. 중복된 메시지 키가 있다

테일과 헤드의 레코드 개수 비율로 압축을 실행한다.
0.5로 설정하면 테일과 헤드 레코드 개수가 동일 한 경우 압축이 실행된다.
비율이 0.9이면 한번에 많은 데이터가 줄어들어 효과는 좋지만 용량을 많이 차지한다.

7. 브로커의 역할 - 복제(Replication)
카프카 장애 허용 시스템으로 동작하도록 하는 원동력이다.
클로스터로 묶인 브로커 중 일부에 장애가 발생하더라도 데이터를 유실하지 않고 안전하게 사용할 수 있다.
카프카의 데이터 복제는 파티션 단위로 이루어진다.
복제 개수의 최소값은 1(복제 없음) 최대값은 브로커 개수만큼 설정하여 사용할 수 있다.

보통 상용에서는 2,3정도로 사용

파티션(리더)에 저장이 되고 다른 브로커의 파티션(팔로워)에 복제된다.
리더의 오프셋에 팔로워가 비교하여 지속적으로 가져간다.(복제)

프로듀셔가 데이터를 가져갈 때는 팔로워에 가져가는게 아니고 리더만 통신하여 가져간다.
따라서 리더 브로커가 다운되면 팔로워 파티션이 승급하여 리더가 되어 통신한다.

네비게이션의 gps를 받는다고 하면 1분에 60개 받는 것중 2,3개 유실되어도 괜찮기 때문에
이럴때는 레플리케이션을 1로 설정한다.
금융정보 같은 것은 3으로도 설정한다.

8. ISR(In-Sync-Replicas)
리더와 팔로워가 모두 싱크된 상태

ISR이 안되었는데 장애가 나면 리더의 데이터가 유실 될 수 있다.
이럴때 팔로워 파티션을 리더로 선출 할 것인지 정하는 것이
unclean.leader.election.enable이다
true이면 ISR 안 된 것도 리더로 선출(유실을 감수함)
false인 경우 해당 브로커가 복구될 때까지 중단

9. 토픽과 파티션
토픽은 카프카에서 데이터를 구분하기 위해 사용되는 단위.
토픽은 1개의 이상의 파티션을 소유하고 있다. 파티션에는 프로듀서가 보낸 데이터들이 들어가 저장되는데
이 데이터를 ‘레코드’라고 부른다. 파티션은 자료구조에서 접하는 큐와 비슷한 구조.
먼저들어간 레코드는 컨슈머가 먼저 가져가게 된다. 다만 큐와 다르게 삭제하지 않는다

토픽 생성시 파티션이 브로커들에 라운드로빈 방식으로 순차적으로 균등하게 리더 파티션들이 생성된다.
균등하게 통신하여 네트워크를 골고루 사용하게 된다.

특정 브로커에 만약 몰르게되면 kafka-reassign-partitions.sh 명령으로 파티션을 재분배할 수 있다.

컨슈며와 파티션은 1대1 관계이다. 파티션은 하나의 컨슈머만 가질 수 있다.
컨슈머의 데이터 처리량을 늘리기 위해서는 파티션을 늘리고 컨슈머를 늘려야한다.

만약 장애 발생 시 하나의 컨슈머가 여러개의 파티션을 처리 할 수도 있다. 

프로듀서는 초당 10개를 보내는데 컨슈머는 초당 1개만 처리할때는 렉이 발생된다
이때는 컨슈머를 10개 늘리고 파티션을 10개 늘려야 한다. 보통 여유롭게 운용해야 함.

파티션 개수를 줄이는 것은 불가능. 

오프셋은 프로듀서가 생성한 레코드에는 존재하지 않고 프로듀서가 전송한 레코드가 브로커에 적재될 떄 오프셋이 지정. 0부터 시작되고 1씩 증가한다.

메시지 키는 처리하고자 하는 메시지 값을 분류하기 위한 용도로 사용되며, 이를 파티셔닝이라고 부름
메시지 키는 파티셔너에 따라 토픽의 파티션 번호가 정해진다.
메시지 키는 필수 값이 아니며 지정하지 않으면 null이다.
메시지 키가 null인 경우는 라운드 로빈으로 파트션에 전달된다.
Null이 아닌 경우 해쉬값에 의해 특정 파티션에 들어간다. 사과 라는 단어는 항상 동일한 파티션에 들어간다.
이럴경우는 같은 파티션에 저장되어 순서보장이 된다.

10. 클라이언트 메타데이터
카프카 클라이언트는 통신하고자하는 리더 파티션의 위치를 알기 위해 데이터를 주고 받기 전에 메타데이터를 브로커로부터 전달 받는다.

메타데이터를 지속적으로 응답받지 못하면 리더 파티션과 통신 할 수 없다.

metadata.max.age.ms: 메타데이터를 강제로 리프래시 하는 간격(기본 5분)
metadata.max.idle.ms: 프로듀서가 유휴 상태일 경우 메타데이터를 캐시에 유지하는 기간

leader_not_available 에러가 발생하면 메타데이터 문제라 자주 리프래시 할 수 있게 한다.
